#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æç°æœ‰æ•°æ®ä¸­çš„æœŸæ•°åˆ†ç±»æƒ…å†µ
ç»Ÿè®¡æ‰€æœ‰ä¸åŒçš„æœŸæ•°è¡¨è¿°ï¼Œä¸ºå»ºç«‹æ ‡å‡†åˆ†ç±»ä½“ç³»åšå‡†å¤‡
"""
import pandas as pd
from pathlib import Path
from collections import Counter
import json

# æ–‡ä»¶è·¯å¾„
CSV_PATH = Path(__file__).parent.parent / "å­¦æ ¡æ€»è§ˆ.csv"
OUTPUT_DIR = Path(__file__).parent.parent / "standardization"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

def analyze_period_classification():
    """åˆ†ææœŸæ•°åˆ†ç±»"""
    print("=" * 60)
    print("æœŸæ•°åˆ†ç±»åˆ†æ")
    print("=" * 60)
    print()
    
    # è¯»å–CSV
    if not CSV_PATH.exists():
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {CSV_PATH}")
        return
    
    print(f"ğŸ“– è¯»å–æ–‡ä»¶: {CSV_PATH}")
    df = pd.read_csv(CSV_PATH, encoding='utf-8-sig')
    print(f"   æ€»è®°å½•æ•°: {len(df)} æ¡")
    print()
    
    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
    if "ç¬¬å‡ æœŸ" not in df.columns:
        print("âŒ æ‰¾ä¸åˆ°'ç¬¬å‡ æœŸ'åˆ—")
        return
    
    # ç»Ÿè®¡æœŸæ•°åˆ†ç±»
    period_col = df["ç¬¬å‡ æœŸ"]
    
    # å»é™¤ç©ºå€¼
    non_null_periods = period_col.dropna()
    print(f"ğŸ“Š éç©ºè®°å½•æ•°: {len(non_null_periods)} æ¡")
    print(f"   ç©ºå€¼è®°å½•æ•°: {len(period_col) - len(non_null_periods)} æ¡")
    print()
    
    # ç»Ÿè®¡æ‰€æœ‰ä¸åŒçš„è¡¨è¿°
    period_counter = Counter()
    for period in non_null_periods:
        period_str = str(period).strip()
        if period_str:
            period_counter[period_str] += 1
    
    # æŒ‰å‡ºç°æ¬¡æ•°æ’åº
    sorted_periods = period_counter.most_common()
    
    print("=" * 60)
    print("æœŸæ•°åˆ†ç±»ç»Ÿè®¡")
    print("=" * 60)
    print()
    print(f"å…±å‘ç° {len(sorted_periods)} ç§ä¸åŒçš„æœŸæ•°è¡¨è¿°ï¼š")
    print()
    
    # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
    for period, count in sorted_periods:
        percentage = (count / len(non_null_periods)) * 100
        print(f"  {period:30s} : {count:5d} æ¬¡ ({percentage:5.2f}%)")
    
    print()
    print("=" * 60)
    print("æ•°æ®è¯¦æƒ…")
    print("=" * 60)
    print()
    
    # ä¿å­˜è¯¦ç»†ç»Ÿè®¡åˆ°JSON
    stats = {
        "total_records": len(df),
        "non_null_records": len(non_null_periods),
        "null_records": len(period_col) - len(non_null_periods),
        "unique_periods": len(sorted_periods),
        "period_distribution": [
            {
                "period": period,
                "count": count,
                "percentage": round((count / len(non_null_periods)) * 100, 2)
            }
            for period, count in sorted_periods
        ]
    }
    
    # ä¿å­˜JSON
    json_path = OUTPUT_DIR / "period_analysis.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    print(f"âœ… è¯¦ç»†ç»Ÿè®¡å·²ä¿å­˜åˆ°: {json_path}")
    
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®ï¼ˆæ¯ç§æœŸæ•°ç±»å‹çš„å‰3æ¡è®°å½•ï¼‰
    print()
    print("=" * 60)
    print("ç¤ºä¾‹æ•°æ®ï¼ˆæ¯ç§æœŸæ•°ç±»å‹çš„å‰3æ¡è®°å½•ï¼‰")
    print("=" * 60)
    print()
    
    examples = {}
    for period, _ in sorted_periods[:10]:  # åªæ˜¾ç¤ºå‰10ç§
        matching_rows = df[df["ç¬¬å‡ æœŸ"] == period].head(3)
        if len(matching_rows) > 0:
            examples[period] = []
            for _, row in matching_rows.iterrows():
                examples[period].append({
                    "å¤§å­¦": row.get("å¤§å­¦", ""),
                    "å­¦éƒ¨": row.get("å­¦éƒ¨", ""),
                    "ç¬¬å‡ æœŸ": row.get("ç¬¬å‡ æœŸ", ""),
                    "æ–¹å¼": row.get("æ–¹å¼", "")
                })
    
    examples_path = OUTPUT_DIR / "period_examples.json"
    with open(examples_path, "w", encoding="utf-8") as f:
        json.dump(examples, f, ensure_ascii=False, indent=2)
    print(f"âœ… ç¤ºä¾‹æ•°æ®å·²ä¿å­˜åˆ°: {examples_path}")
    
    # ç”Ÿæˆå»ºè®®çš„æ ‡å‡†åˆ†ç±»
    print()
    print("=" * 60)
    print("å»ºè®®çš„æ ‡å‡†åˆ†ç±»ï¼ˆåˆæ­¥ï¼‰")
    print("=" * 60)
    print()
    print("åŸºäºåˆ†æç»“æœï¼Œå»ºè®®çš„æ ‡å‡†åˆ†ç±»ï¼š")
    print()
    
    # ç®€å•çš„åˆ†ç±»å»ºè®®ï¼ˆåŸºäºå…³é”®è¯ï¼‰
    suggested_categories = {
        "åªæœ‰ä¸€æœŸ": [],
        "å‰æœŸ": [],
        "åæœŸ": [],
        "å‰æœŸ+åæœŸ": [],
        "å…¶ä»–": []
    }
    
    for period, count in sorted_periods:
        period_lower = str(period).lower()
        if "åªæœ‰ä¸€æœŸ" in period or "å˜ç‹¬" in period or "ä¸€æœŸã®ã¿" in period:
            suggested_categories["åªæœ‰ä¸€æœŸ"].append({"period": period, "count": count})
        elif "å‰æœŸ" in period and "åæœŸ" in period:
            suggested_categories["å‰æœŸ+åæœŸ"].append({"period": period, "count": count})
        elif "å‰æœŸ" in period:
            suggested_categories["å‰æœŸ"].append({"period": period, "count": count})
        elif "åæœŸ" in period or "å¾ŒæœŸ" in period:
            suggested_categories["åæœŸ"].append({"period": period, "count": count})
        else:
            suggested_categories["å…¶ä»–"].append({"period": period, "count": count})
    
    for category, periods in suggested_categories.items():
        if periods:
            total_count = sum(p["count"] for p in periods)
            print(f"{category}:")
            for p in periods:
                print(f"  - {p['period']:30s} ({p['count']} æ¬¡)")
            print(f"  å°è®¡: {total_count} æ¬¡")
            print()
    
    # ä¿å­˜å»ºè®®åˆ†ç±»
    suggested_path = OUTPUT_DIR / "period_suggested_categories.json"
    with open(suggested_path, "w", encoding="utf-8") as f:
        json.dump(suggested_categories, f, ensure_ascii=False, indent=2)
    print(f"âœ… å»ºè®®åˆ†ç±»å·²ä¿å­˜åˆ°: {suggested_path}")
    
    print()
    print("=" * 60)
    print("åˆ†æå®Œæˆï¼")
    print("=" * 60)
    print()
    print("ä¸‹ä¸€æ­¥ï¼š")
    print("1. æŸ¥çœ‹ standardization/period_analysis.json äº†è§£è¯¦ç»†ç»Ÿè®¡")
    print("2. æŸ¥çœ‹ standardization/period_examples.json æŸ¥çœ‹ç¤ºä¾‹æ•°æ®")
    print("3. æŸ¥çœ‹ standardization/period_suggested_categories.json æŸ¥çœ‹å»ºè®®åˆ†ç±»")
    print("4. åŸºäºè¿™äº›ä¿¡æ¯ï¼Œå»ºç«‹æœ€ç»ˆçš„æ ‡å‡†åˆ†ç±»ä½“ç³»")


if __name__ == "__main__":
    analyze_period_classification()
