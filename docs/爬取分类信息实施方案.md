# 爬取分类信息实施方案

## 🎯 目标

通过爬取各大学官网，收集所有大学实际使用的期数和选考方式表述，为建立标准分类体系提供数据基础。

---

## 📋 实施步骤

### 阶段1：准备阶段（1-2天）

#### 1.1 创建大学URL映射表

**问题**：每个大学的网站结构不同，需要知道每个大学的招生页面URL

**解决方案**：创建一个映射表，手动填写各大学的招生页面URL

**文件**：`crawled_data/university_urls.json`

```json
{
  "東京大学": {
    "base_url": "https://www.u-tokyo.ac.jp",
    "admission_url": "https://www.u-tokyo.ac.jp/admission/undergraduate/foreign.html",
    "notes": "外国人入試页面"
  },
  "京都大学": {
    "base_url": "https://www.kyoto-u.ac.jp",
    "admission_url": "https://www.kyoto-u.ac.jp/ja/admissions/undergraduate/international",
    "notes": "留学生入試页面"
  },
  ...
}
```

#### 1.2 编写基础爬虫框架

**功能**：
- 读取大学URL映射表
- 访问各大学招生页面
- 提取文本内容
- 保存原始数据

### 阶段2：试点爬取（2-3天）

#### 2.1 选择试点大学

**建议选择**：
- 10-20所代表性大学
- 包括：国立大学、私立大学、不同地区
- 例如：東京大学、京都大学、早稲田大学、慶應義塾大学等

#### 2.2 运行试点爬虫

**目标**：
- 测试爬虫逻辑
- 发现常见问题
- 优化爬虫代码

#### 2.3 分析试点结果

**分析内容**：
- 哪些信息可以自动提取
- 哪些需要人工处理
- 网站结构的共同模式

### 阶段3：全面爬取（1-2周）

#### 3.1 扩展URL映射表

**任务**：
- 为所有170所大学填写URL
- 可以分批进行（每天填写20-30所）

#### 3.2 运行全面爬虫

**方式**：
- 可以分批运行（每天爬取20-30所）
- 后台运行，不影响其他工作

#### 3.3 数据验证

**验证内容**：
- 检查爬取成功率
- 验证数据质量
- 识别需要重新爬取的大学

### 阶段4：数据分析（3-5天）

#### 4.1 统计所有不同表述

**任务**：
- 统计期数的所有不同表述
- 统计选考方式的所有不同表述
- 统计校内考的所有不同表述
- 统计EJU科目的所有不同表述

#### 4.2 建立标准分类体系

**基于爬取结果**：
- 识别同义词和变体
- 建立互斥且全面的分类
- 编写分类说明文档

#### 4.3 生成映射表

**任务**：
- 建立现有数据 → 标准分类的映射
- 建立爬取数据 → 标准分类的映射

---

## 🛠️ 技术实现

### 爬虫架构

```
scripts/crawlers/
├── base_crawler.py              # 基础爬虫类
├── crawl_classification_info.py # 主爬虫脚本
├── parsers/
│   ├── html_parser.py          # HTML解析器
│   ├── pdf_parser.py           # PDF解析器
│   └── text_extractor.py       # 文本提取器
└── utils/
    ├── url_manager.py          # URL管理
    └── data_saver.py           # 数据保存
```

### 数据存储结构

```
crawled_data/
├── classification_info/
│   ├── raw_data/               # 原始数据
│   │   ├── tokyo_univ.json
│   │   ├── kyoto_univ.json
│   │   └── ...
│   ├── statistics/             # 统计数据
│   │   ├── period_statistics.json
│   │   ├── method_statistics.json
│   │   └── ...
│   └── reports/               # 爬取报告
│       ├── crawl_report_20250217.txt
│       └── ...
└── university_urls.json        # 大学URL映射表
```

---

## 📊 预期产出

### 爬取完成后将得到：

1. **所有大学官网的实际表述**
   - 期数：所有不同的期数表述及使用该表述的大学
   - 选考方式：所有不同的选考方式表述及使用该表述的大学
   - 校内考：所有不同的校内考表述
   - EJU科目：所有不同的EJU科目要求

2. **统计报告**
   - 每种表述出现的次数
   - 哪些大学使用哪种表述
   - 是否有地域或学校类型差异

3. **标准分类体系**（基于真实数据）
   - 互斥且全面的分类
   - 基于实际使用情况
   - 有数据支撑

---

## ⏱️ 时间估算

### 准备阶段
- **创建URL映射表**：1-2天（可以分批进行）
- **编写爬虫框架**：1天

### 试点阶段
- **试点爬取**：1天
- **分析优化**：1-2天

### 全面爬取
- **扩展URL映射表**：3-5天（每天填写20-30所）
- **运行爬虫**：1-2周（可以分批进行，每天爬取20-30所）

### 数据分析
- **统计和分析**：3-5天
- **建立标准分类**：2-3天

**总计**：约3-4周（可以并行进行，实际时间可能更短）

---

## 💡 实施建议

### 建议1：先做试点

**理由**：
- 测试爬虫逻辑
- 发现常见问题
- 优化代码
- 确认可行性

**试点大学建议**：
- 東京大学、京都大学、大阪大学（国立）
- 早稲田大学、慶應義塾大学（私立）
- 名古屋大学、九州大学（地方国立）
- 其他代表性大学

### 建议2：分批进行

**URL映射表**：
- 每天填写20-30所大学的URL
- 一周完成所有大学

**爬取**：
- 每天爬取20-30所大学
- 一周完成所有大学
- 可以后台运行

### 建议3：数据验证

**每个阶段都要验证**：
- 试点阶段：验证爬取逻辑
- 全面爬取：验证数据质量
- 数据分析：验证分类合理性

---

## 🚀 立即开始

### 我现在可以帮您：

1. **创建URL映射表模板**
   - 提供Excel模板
   - 您可以填写各大学的URL

2. **编写基础爬虫框架**
   - 读取URL映射表
   - 访问页面并提取文本
   - 保存原始数据

3. **编写试点爬虫**
   - 选择10-20所大学
   - 测试爬取逻辑

**您希望我从哪里开始？**

建议顺序：
1. 先创建URL映射表模板（您可以填写）
2. 编写基础爬虫框架
3. 选择试点大学测试
4. 确认可行后扩展到所有大学

这样我们可以逐步推进，每一步都验证可行性。
