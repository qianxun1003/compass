# 统一爬取框架设计方案

## 🎯 核心目标

**创建一个统一的爬取框架，一次性爬取所有需要的数据，包括：**
- 已有的数据（验证准确性）
- 缺失的数据（补全）
- 所有您列出的数据需求

---

## 📋 一、需要爬取的所有数据清单

### 基础信息
1. ✅ 学部及学科分类（文/理/文理皆可）
2. ✅ 不同学部的地理位置
3. ✅ 大学报考属于前期还是后期？（需要重新爬取验证）
4. ✅ 大学选考的方式？（需要重新爬取验证）
5. ✅ 可否并愿？

### 校内考信息
6. ✅ 校内考的有无？
7. ✅ 一次选考？二次选考？
8. ✅ 校内考对应的时间
9. ✅ 校内考要考什么？考试的形式？

### 出愿时间
10. ✅ 出愿开始时间
11. ✅ 出愿结束时间
12. ✅ 邮寄开始时间
13. ✅ 邮寄截止时间
14. ✅ 必着/消印

### 出愿材料（缺失）
15. ❌ **出愿材料清单**
16. ❌ **推荐信需要吗？**
17. ❌ **出愿流程**

### 成绩要求（部分缺失）
18. ✅ EJU需要的科目（需要重新爬取验证）
19. ❌ **EJU科目推荐分数**
20. ✅ 能使用的EJU时间期限
21. ❌ **英语成绩类型**（TOEFL/TOEIC/IELTS）
22. ❌ **英语成绩推荐分数**
23. ❌ **JLPT等级要求**（N1/N2）
24. ❌ **JLPT分数要求**
25. ❌ **成绩的特殊要求**（哪些科目更重要、哪些不需要等）

### 合格情况（缺失）
26. ❌ **往年的合格情况**（报录比）
27. ❌ **合格人的成绩情况**（如果公开）

---

## 🏗️ 二、统一爬取框架设计

### 2.1 框架结构

```
统一爬取框架
    ↓
访问大学招生页面
    ↓
提取所有需要的信息
    ↓
保存结构化数据
    ↓
生成统计报告
```

### 2.2 数据提取模块

**模块化设计，每个模块负责提取一类信息**：

```
1. 基础信息提取模块
   - 学部、学科、地理位置
   - 文理分类
   
2. 期数信息提取模块
   - 前期/后期/第一期等
   - 所有可能的表述
   
3. 选考方式提取模块
   - 外国人入試/一般入試等
   - 所有可能的表述
   
4. 校内考信息提取模块
   - 有无校内考
   - 一次/二次选考
   - 考试形式和时间
   
5. 出愿时间提取模块
   - 网上出愿时间
   - 邮寄时间
   - 必着/消印
   
6. 出愿材料提取模块
   - 材料清单
   - 推荐信要求
   - 出愿流程
   
7. 成绩要求提取模块
   - EJU科目和分数
   - 英语成绩类型和分数
   - JLPT等级和分数
   
8. 合格情况提取模块
   - 报录比
   - 合格人成绩（如果公开）
```

---

## 📊 三、URL需求分析

### 3.1 URL是否需要分类？

**答案：需要，但可以自动处理**

**原因**：
- 不同信息可能在不同页面
- 例如：
  - 基础信息：可能在"入試要項"页面
  - 出愿材料：可能在"出願書類"页面
  - 合格情况：可能在"合格実績"页面

**解决方案**：
1. **主URL**：每个大学提供一个主招生页面URL
2. **自动发现**：爬虫自动查找相关链接
3. **手动补充**：如果需要，可以手动指定特定页面的URL

### 3.2 URL映射表结构

```json
{
  "東京大学": {
    "base_url": "https://www.u-tokyo.ac.jp",
    "main_admission_url": "https://www.u-tokyo.ac.jp/admission/undergraduate/foreign.html",
    "additional_urls": {
      "出願書類": "https://www.u-tokyo.ac.jp/admission/undergraduate/foreign/documents.html",
      "合格実績": "https://www.u-tokyo.ac.jp/admission/undergraduate/foreign/results.html"
    },
    "notes": "主页面包含大部分信息，其他页面可选"
  }
}
```

**简化版**（推荐）：
```json
{
  "東京大学": {
    "main_admission_url": "https://www.u-tokyo.ac.jp/admission/undergraduate/foreign.html",
    "notes": "主页面URL，爬虫会自动查找其他相关页面"
  }
}
```

---

## 🛠️ 四、统一爬取框架实现

### 4.1 框架特点

**一次性爬取所有信息**：
- ✅ 访问一个主URL
- ✅ 自动提取所有需要的信息
- ✅ 自动查找相关页面（如果需要）
- ✅ 保存完整的数据结构

**智能提取**：
- ✅ 使用关键词匹配
- ✅ 使用正则表达式
- ✅ 使用HTML结构分析
- ✅ 处理PDF文件（如果存在）

**容错处理**：
- ✅ 如果某个信息找不到，标记为"未找到"
- ✅ 继续提取其他信息
- ✅ 生成详细的提取报告

### 4.2 数据结构设计

**输出数据结构**：

```json
{
  "university": "東京大学",
  "department": "理科一類",
  "crawled_at": "2025-02-17T10:30:00",
  "source_url": "https://www.u-tokyo.ac.jp/admission/...",
  
  "基础信息": {
    "学部": "理科一類",
    "学科": null,
    "地理位置": "東京都",
    "文理": "理",
    "status": "found"  // found / not_found / needs_review
  },
  
  "期数信息": {
    "原始表述": "只有一期",
    "所有可能的表述": ["只有一期", "単独選抜"],
    "status": "found"
  },
  
  "选考方式": {
    "原始表述": "外国人入試",
    "所有可能的表述": ["外国人入試", "外国人特別選抜"],
    "status": "found"
  },
  
  "校内考信息": {
    "有无": "有",
    "一次选考": {
      "名称": "一次选考",
      "时间": "2026-02-25",
      "形式": "小论文",
      "status": "found"
    },
    "二次选考": {
      "名称": "二次选考",
      "时间": "2026-03-04",
      "形式": "面试（线下）",
      "status": "found"
    }
  },
  
  "出愿时间": {
    "网上出愿开始": "2025-12-01",
    "网上出愿截止": "2025-12-05",
    "邮寄开始": "2025-12-01",
    "邮寄截止": "2025-12-05",
    "必着/消印": "必着",
    "status": "found"
  },
  
  "出愿材料": {
    "材料清单": ["入学志愿书", "成绩证明书", ...],
    "推荐信要求": "需要2封",
    "出愿流程": "1. 网上出愿 2. 邮寄材料 ...",
    "status": "found"  // 或 "not_found"
  },
  
  "成绩要求": {
    "EJU科目": {
      "需要的科目": ["日语", "数学コース2"],
      "推荐分数": {
        "日语": "350-400",
        "数学2": "180-200"
      },
      "status": "found"
    },
    "英语": {
      "是否需要": "要",
      "成绩类型": "TOEFL",
      "推荐分数": "80以上",
      "status": "found"
    },
    "JLPT": {
      "是否需要": "不要",
      "等级要求": null,
      "分数要求": null,
      "status": "found"
    }
  },
  
  "合格情况": {
    "报录比": {
      "2024": {"报考": 150, "合格": 30, "比例": 0.2},
      "2023": {"报考": 140, "合格": 28, "比例": 0.2}
    },
    "合格人成绩": null,  // 如果公开
    "status": "found"  // 或 "not_found"
  },
  
  "提取质量": {
    "完整度": 0.95,  // 0-1，提取到的信息比例
    "需要人工审核": false,
    "提取问题": []  // 如果有问题，记录在这里
  }
}
```

---

## 📝 五、您需要提供的信息

### 最小需求：主URL（推荐）

**只需要提供每个大学的主招生页面URL**

**格式**：
```json
{
  "東京大学": "https://www.u-tokyo.ac.jp/admission/undergraduate/foreign.html",
  "京都大学": "https://www.kyoto-u.ac.jp/ja/admissions/undergraduate/international",
  ...
}
```

**为什么只需要主URL？**
- 爬虫会自动查找相关链接
- 大部分信息通常在主页面
- 如果需要，可以后续补充特定页面URL

### 可选：补充URL（如果需要）

**如果某些信息在特定页面，可以补充**：
```json
{
  "東京大学": {
    "main": "https://www.u-tokyo.ac.jp/admission/undergraduate/foreign.html",
    "出願書類": "https://www.u-tokyo.ac.jp/admission/undergraduate/foreign/documents.html",
    "合格実績": "https://www.u-tokyo.ac.jp/admission/undergraduate/foreign/results.html"
  }
}
```

---

## 🚀 六、实施计划

### 阶段1：编写统一爬取框架（我来做）

**任务**：
1. 设计统一的数据结构
2. 编写各个信息提取模块
3. 编写主爬虫框架
4. 编写数据保存和统计功能

**时间**：2-3天

### 阶段2：创建URL映射表（您来做）

**任务**：
1. 填写各大学的主招生页面URL
2. 可以分批进行（每天10-20所）

**时间**：1-2周（可以并行进行）

### 阶段3：试点测试（我们一起）

**任务**：
1. 选择10-20所大学测试
2. 验证爬取效果
3. 优化代码

**时间**：2-3天

### 阶段4：全面爬取（我来做）

**任务**：
1. 运行爬虫爬取所有大学
2. 生成完整数据
3. 生成统计报告

**时间**：1-2周（可以后台运行）

### 阶段5：数据分析和标准化（我们一起）

**任务**：
1. 分析所有爬取到的表述
2. 建立标准分类体系
3. 映射现有数据

**时间**：3-5天

---

## ✅ 七、可行性确认

### 可以实现吗？

**✅ 完全可以！**

**理由**：
1. ✅ 技术可行：Python爬虫可以访问网页、提取信息
2. ✅ 结构清晰：模块化设计，每个模块负责一类信息
3. ✅ 容错处理：如果某个信息找不到，不影响其他信息
4. ✅ 灵活扩展：可以随时添加新的信息提取模块

### 需要注意的问题

1. **网站结构多样化**
   - 每个大学的网站结构不同
   - 需要通用的提取逻辑 + 特定网站的适配

2. **信息可能分散**
   - 不同信息可能在不同页面
   - 爬虫会自动查找相关链接

3. **PDF文件处理**
   - 很多大学用PDF发布招生简章
   - 需要PDF解析功能

4. **数据质量**
   - 某些信息可能找不到
   - 需要标记"未找到"，后续人工补充

---

## 📋 八、您需要做什么

### 最小工作量：只提供URL

**您只需要**：
1. 访问各大学官网
2. 找到留学生入試页面
3. 复制URL
4. 填写到映射表中

**格式**：
```json
{
  "大学名": "URL"
}
```

**就是这么简单！**

### 可选：补充特定页面URL

**如果需要更准确的数据**：
- 可以补充特定页面的URL（如出愿材料页面、合格情况页面）
- 但不是必需的

---

## 🎯 九、总结

### 可以实现
✅ **完全可以实现统一爬取框架**

### 您需要提供
✅ **只需要各大学的主招生页面URL**

### URL是否需要分类
✅ **不需要分类，只需要主URL**
- 爬虫会自动查找相关页面
- 如果需要，可以后续补充特定页面URL

### 优势
✅ **一次性爬取所有信息**
✅ **统一的数据结构**
✅ **自动提取和保存**
✅ **生成完整报告**

---

## 🚀 下一步

### 我现在可以立即开始：

1. **编写统一爬取框架**
   - 设计数据结构
   - 编写各个提取模块
   - 编写主爬虫脚本

2. **创建URL映射表模板**
   - 提供简单的格式
   - 您只需要填写URL

3. **编写使用说明**
   - 如何填写URL
   - 如何运行爬虫
   - 如何查看结果

**您希望我现在就开始编写统一爬取框架吗？**

我可以立即开始，预计2-3天完成框架，然后您就可以开始填写URL了。
